A web based project consisting of a translator that converts hand signs or gestures into text and speech.
The project is helpful for the speech-impaired population as well as others. 
The project aims to ease the communication between speech-impaired individuals and others in real-time, considering most of the world's population is unfamiliar with sign language. 
Machine learning and Python can assist with the cause. 
The software is developed using neural networks and Python libraries such as Tensorflow, MediaPipe Holistic and OpenCV, and coding platforms like Visual studio and Jupyter Notebook.
Current model converts only 3 gestures: Hello, I love you and Thank you
